{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NasimRidoy/Ingredient-extraction/blob/main/Ingredient_extraction_Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# !pip uninstall -y torch torchvision torchaudio\n",
        "# !pip install torch==2.7.1 torchvision==0.22.1 torchaudio==2.7.1\n",
        "\n",
        "\n",
        "# !pip install transformers==4.53.3\n",
        "# !pip install datasets evaluate -q\n",
        "# !pip install seqeval\n",
        "# !pip install surya-ocr\n",
        "!pip install opencv-python numpy\n",
        "\n",
        "import transformers\n",
        "print(transformers.__version__) # 4.53.3 for surya-ocr\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "import torchvision\n",
        "print(torchvision.__version__)\n",
        "import torchaudio\n",
        "print(torchaudio.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQxL7WIeCE3q",
        "outputId": "d2468e0f-5f7b-4454-d9d4-358bbfb23e78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python\n",
            "Successfully installed opencv-python-4.12.0.88\n",
            "4.55.2\n",
            "2.6.0+cu124\n",
            "0.21.0+cu124\n",
            "2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80t9Z2IoC2EH",
        "outputId": "ae169ec1-d47d-4fb7-e5a9-10235988b95f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "detects lines perfect. gives output image and json. BUT TAKES TIME (35 sec in CPU runtime)"
      ],
      "metadata": {
        "id": "npqWD-99ozJW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5hvpHRCq8gY"
      },
      "outputs": [],
      "source": [
        "# !surya_detect /content/final_processed_image1.png --images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from PIL import Image, ImageDraw\n",
        "from surya.detection import DetectionPredictor\n",
        "\n",
        "# --- Input image ---\n",
        "IMAGE_PATH = \"/content/drive/MyDrive/Thesis/surya/surya_input_images/in1.jpg\"\n",
        "\n",
        "# --- Output directory ---\n",
        "detected_dir = os.path.join(os.path.dirname(IMAGE_PATH), \"detected_images\")\n",
        "os.makedirs(detected_dir, exist_ok=True)\n",
        "\n",
        "# --- Initialize detection predictor ---\n",
        "detection_predictor = DetectionPredictor(device=\"cuda\")\n",
        "\n",
        "# --- Open image ---\n",
        "image = Image.open(IMAGE_PATH).convert(\"RGB\")\n",
        "\n",
        "# --- Run text line detection ---\n",
        "detections = detection_predictor([image])[0]  # returns TextDetectionResult\n",
        "\n",
        "# --- Prepare output file paths ---\n",
        "img_name = os.path.splitext(os.path.basename(IMAGE_PATH))[0]\n",
        "img_out_path = os.path.join(detected_dir, f\"{img_name}_detected.jpg\")\n",
        "json_out_path = os.path.join(detected_dir, f\"{img_name}_detections.json\")\n",
        "\n",
        "# --- Draw bounding boxes on image ---\n",
        "draw = ImageDraw.Draw(image)\n",
        "for polybox in detections.bboxes:\n",
        "    x_min, y_min, x_max, y_max = map(int, polybox.bbox)\n",
        "    draw.rectangle([x_min, y_min, x_max, y_max], outline=\"red\", width=2)\n",
        "    draw.text((x_min, max(0, y_min - 10)), f\"{polybox.confidence:.2f}\", fill=\"red\")\n",
        "\n",
        "# --- Save annotated image ---\n",
        "image.save(img_out_path)\n",
        "\n",
        "# --- Save detections as JSON ---\n",
        "detections_list = []\n",
        "for polybox in detections.bboxes:\n",
        "    detections_list.append({\n",
        "        \"polygon\": polybox.polygon,\n",
        "        \"confidence\": float(polybox.confidence),\n",
        "        \"bbox\": list(map(int, polybox.bbox))\n",
        "    })\n",
        "\n",
        "with open(json_out_path, \"w\") as f:\n",
        "    json.dump(detections_list, f, indent=4)\n",
        "\n",
        "print(f\"✅ Processed: {img_name}\")\n",
        "print(f\"   Saved detected image → {img_out_path}\")\n",
        "print(f\"   Saved detections JSON → {json_out_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lqy-3BX1unG",
        "outputId": "9aab1ff1-73e8-4718-df4a-3e6443127afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Processed: in1\n",
            "   Saved detected image → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1_detected.jpg\n",
            "   Saved detections JSON → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1_detections.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for looping all the images"
      ],
      "metadata": {
        "id": "y4-ol_Vz2KD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import json\n",
        "# from PIL import Image, ImageDraw\n",
        "# from surya.detection import DetectionPredictor\n",
        "\n",
        "# # --- Input directory containing images ---\n",
        "# IMAGE_DIR = \"/content/drive/MyDrive/Thesis/surya/surya_input_images\"\n",
        "\n",
        "# # --- Initialize detection predictor once ---\n",
        "# detection_predictor = DetectionPredictor(device=\"cuda\")\n",
        "\n",
        "# # --- Prepare output directory ---\n",
        "# detected_dir = os.path.join(IMAGE_DIR, \"detected_images\")\n",
        "# os.makedirs(detected_dir, exist_ok=True)\n",
        "\n",
        "# # --- Loop over all image files in IMAGE_DIR ---\n",
        "# for filename in os.listdir(IMAGE_DIR):\n",
        "#     if not filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "#         continue  # skip non-image files\n",
        "\n",
        "#     IMAGE_PATH = os.path.join(IMAGE_DIR, filename)\n",
        "#     image = Image.open(IMAGE_PATH).convert(\"RGB\")\n",
        "\n",
        "#     # Run text line detection\n",
        "#     detections = detection_predictor([image])[0]  # returns TextDetectionResult\n",
        "\n",
        "#     # Prepare output file paths\n",
        "#     img_name = os.path.splitext(filename)[0]\n",
        "#     img_out_path = os.path.join(detected_dir, f\"{img_name}_detected.jpg\")\n",
        "#     json_out_path = os.path.join(detected_dir, f\"{img_name}_detections.json\")\n",
        "\n",
        "#     # Draw bounding boxes on image\n",
        "#     draw = ImageDraw.Draw(image)\n",
        "#     for polybox in detections.bboxes:\n",
        "#         x_min, y_min, x_max, y_max = map(int, polybox.bbox)\n",
        "#         draw.rectangle([x_min, y_min, x_max, y_max], outline=\"red\", width=2)\n",
        "#         draw.text((x_min, max(0, y_min - 10)), f\"{polybox.confidence:.2f}\", fill=\"red\")\n",
        "\n",
        "#     # Save annotated image\n",
        "#     image.save(img_out_path)\n",
        "\n",
        "#     # Save detections as JSON\n",
        "#     detections_list = []\n",
        "#     for polybox in detections.bboxes:\n",
        "#         detections_list.append({\n",
        "#             \"polygon\": polybox.polygon,\n",
        "#             \"confidence\": float(polybox.confidence),\n",
        "#             \"bbox\": list(map(int, polybox.bbox))\n",
        "#         })\n",
        "\n",
        "#     with open(json_out_path, \"w\") as f:\n",
        "#         json.dump(detections_list, f, indent=4)\n",
        "\n",
        "#     print(f\"✅ Processed: {filename}\")\n",
        "#     print(f\"   Saved detected image → {img_out_path}\")\n",
        "#     print(f\"   Saved detections JSON → {json_out_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XIoEy_BtOg8",
        "outputId": "a98346a4-7727-4af7-f27a-af93873b054e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  3.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Processed: original_image.jpg\n",
            "   Saved detected image → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/original_image_detected.jpg\n",
            "   Saved detections JSON → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/original_image_detections.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Processed: final_processed_image.png\n",
            "   Saved detected image → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/final_processed_image_detected.jpg\n",
            "   Saved detections JSON → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/final_processed_image_detections.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Processed: final_processed_image (1).png\n",
            "   Saved detected image → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/final_processed_image (1)_detected.jpg\n",
            "   Saved detections JSON → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/final_processed_image (1)_detections.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Processed: in1.jpg\n",
            "   Saved detected image → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1_detected.jpg\n",
            "   Saved detections JSON → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1_detections.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Processed: product.jpg\n",
            "   Saved detected image → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/product_detected.jpg\n",
            "   Saved detections JSON → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/product_detections.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Processed: today1.jpg\n",
            "   Saved detected image → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/today1_detected.jpg\n",
            "   Saved detections JSON → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/today1_detections.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import glob, shutil\n",
        "\n",
        "# for ckpt in glob.glob(\"/content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/today1/\"):\n",
        "#     shutil.rmtree(ckpt, ignore_errors=True)"
      ],
      "metadata": {
        "id": "I6jLp_Uwntws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CROP (works fast in GPU)"
      ],
      "metadata": {
        "id": "X7Pq7lVdFePu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "\n",
        "# --- Paths for a single image ---\n",
        "original_dir = os.path.dirname(IMAGE_PATH)\n",
        "image_name = img_name = os.path.splitext(os.path.basename(IMAGE_PATH))[0]  # without extension\n",
        "json_file = os.path.join(original_dir, \"detected_images\", f\"{image_name}_detections.json\")\n",
        "\n",
        "# --- Open the corresponding original image ---\n",
        "orig_img_path = os.path.join(original_dir, f\"{image_name}.png\")  # try .png\n",
        "if not os.path.exists(orig_img_path):\n",
        "    orig_img_path = os.path.join(original_dir, f\"{image_name}.jpg\")  # fallback .jpg\n",
        "    if not os.path.exists(orig_img_path):\n",
        "        raise FileNotFoundError(f\"Original image not found for {image_name}\")\n",
        "\n",
        "image = Image.open(orig_img_path).convert(\"RGB\")\n",
        "\n",
        "# --- Load bounding boxes from JSON ---\n",
        "with open(json_file, \"r\") as f:\n",
        "    bboxes_data = json.load(f)\n",
        "\n",
        "# --- Create output folder for cropped images ---\n",
        "crop_dir = os.path.join(original_dir, \"detected_images\", image_name)\n",
        "os.makedirs(crop_dir, exist_ok=True)\n",
        "\n",
        "# --- Sort bounding boxes by y_min (top) ---\n",
        "sorted_boxes = sorted(bboxes_data, key=lambda b: b[\"bbox\"][1])\n",
        "\n",
        "# --- Crop and save each bounding box ---\n",
        "for i, box in enumerate(sorted_boxes, start=1):\n",
        "    x_min, y_min, x_max, y_max = map(int, box[\"bbox\"])\n",
        "    cropped = image.crop((x_min, y_min, x_max, y_max))\n",
        "    out_path = os.path.join(crop_dir, f\"crop_{i}.jpg\")\n",
        "    cropped.save(out_path)\n",
        "\n",
        "print(f\"✅ Saved {len(sorted_boxes)} cropped images for {image_name} → {crop_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heP8BKDd2aOj",
        "outputId": "e7167f7e-fa00-4703-c349-593127a01d52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 16 cropped images for in1 → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for looping all images to crop"
      ],
      "metadata": {
        "id": "N_lVAfYJ21xF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import json\n",
        "# from PIL import Image\n",
        "\n",
        "# # Directories\n",
        "# original_dir = \"/content/drive/MyDrive/Thesis/surya/surya_input_images\"\n",
        "# detected_dir = os.path.join(original_dir, \"detected_images\")\n",
        "\n",
        "# # Loop over all detection JSON files\n",
        "# for json_file in os.listdir(detected_dir):\n",
        "#     if not json_file.endswith(\"_detections.json\"):\n",
        "#         continue\n",
        "\n",
        "#     json_path = os.path.join(detected_dir, json_file)\n",
        "#     img_name = json_file.replace(\"_detections.json\", \"\")\n",
        "\n",
        "#     # Open the corresponding original image (not the detected one)\n",
        "#     orig_img_path = os.path.join(original_dir, f\"{img_name}.png\")  # adjust extension if needed\n",
        "#     if not os.path.exists(orig_img_path):\n",
        "#         orig_img_path = os.path.join(original_dir, f\"{img_name}.jpg\")\n",
        "#         if not os.path.exists(orig_img_path):\n",
        "#             print(f\"⚠️ Original image not found for {img_name}, skipping\")\n",
        "#             continue\n",
        "\n",
        "#     image = Image.open(orig_img_path).convert(\"RGB\")\n",
        "\n",
        "#     # Load bounding boxes from JSON\n",
        "#     with open(json_path, \"r\") as f:\n",
        "#         bboxes_data = json.load(f)\n",
        "\n",
        "#     # Create output folder for cropped images\n",
        "#     crop_dir = os.path.join(detected_dir, img_name)\n",
        "#     os.makedirs(crop_dir, exist_ok=True)\n",
        "\n",
        "#     # Sort bounding boxes by y_min (top)\n",
        "#     sorted_boxes = sorted(bboxes_data, key=lambda b: b[\"bbox\"][1])\n",
        "\n",
        "#     # Crop and save each bounding box\n",
        "#     for i, box in enumerate(sorted_boxes, start=1):\n",
        "#         x_min, y_min, x_max, y_max = map(int, box[\"bbox\"])\n",
        "#         cropped = image.crop((x_min, y_min, x_max, y_max))\n",
        "#         out_path = os.path.join(crop_dir, f\"crop_{i}.jpg\")\n",
        "#         cropped.save(out_path)\n",
        "\n",
        "#     print(f\"✅ Saved {len(sorted_boxes)} cropped images for {img_name} → {crop_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qawaAvprFdiO",
        "outputId": "0d76bc5a-f4d1-48b3-c56b-521e56f38011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 39 cropped images for product → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/product\n",
            "✅ Saved 16 cropped images for in1 → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1\n",
            "✅ Saved 12 cropped images for original_image → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/original_image\n",
            "✅ Saved 15 cropped images for today1 → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/today1\n",
            "✅ Saved 53 cropped images for final_processed_image → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/final_processed_image\n",
            "✅ Saved 22 cropped images for final_processed_image (1) → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/final_processed_image (1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tr-ocr apply"
      ],
      "metadata": {
        "id": "OfDC9l3xpvpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers==4.44.2 accelerate\n"
      ],
      "metadata": {
        "id": "BctqlcJnpxT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForVision2Seq, AutoImageProcessor\n",
        "from PIL import Image\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# =========================\n",
        "# Load TrOCR model\n",
        "# =========================\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/trocr-large-printed\")\n",
        "model = AutoModelForVision2Seq.from_pretrained(\"microsoft/trocr-large-printed\")\n",
        "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/trocr-large-printed\")\n",
        "\n",
        "# Use GPU if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "# =========================\n",
        "# Folder containing cropped images for a single original image\n",
        "# =========================\n",
        "image_folder = os.path.join(original_dir, \"detected_images\")\n",
        "original_image_name = \"in1\"  # the folder with cropped images\n",
        "cropped_folder = os.path.join(image_folder, original_image_name)\n",
        "\n",
        "# List all cropped images in that folder\n",
        "image_paths = [os.path.join(cropped_folder, f)\n",
        "               for f in os.listdir(cropped_folder)\n",
        "               if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
        "\n",
        "# =========================\n",
        "# Batch size\n",
        "# =========================\n",
        "batch_size = 1  # adjust based on GPU memory\n",
        "\n",
        "# =========================\n",
        "# Function to process a batch of images\n",
        "# =========================\n",
        "def ocr_batch(image_paths_batch):\n",
        "    images = [Image.open(p).convert(\"RGB\") for p in image_paths_batch]\n",
        "    pixel_values = image_processor(images, return_tensors=\"pt\").pixel_values.to(device)\n",
        "    generated_ids = model.generate(pixel_values)\n",
        "    texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "    return texts\n",
        "\n",
        "# =========================\n",
        "# Process all images in batches\n",
        "# =========================\n",
        "ocr_texts = []\n",
        "for i in range(0, len(image_paths), batch_size):\n",
        "    batch_paths = image_paths[i:i+batch_size]\n",
        "    batch_texts = ocr_batch(batch_paths)\n",
        "    ocr_texts.extend(batch_texts)\n",
        "\n",
        "# =========================\n",
        "# Print results\n",
        "# =========================\n",
        "for img_path, text in zip(image_paths, ocr_texts):\n",
        "    print(f\"{img_path}: {text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AKSB_DgpznH",
        "outputId": "901447ff-7399-40d5-ecc4-323166f4754a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-large-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1/crop_1.jpg: IG\n",
            "/content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1/crop_2.jpg: INGREDIENTS:\n",
            "/content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1/crop_3.jpg: POTATO, REFINED PALMOLEIN OIL, BENGAL GRAM\n",
            "/content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1/crop_4.jpg: FLOUR (BESAN), POTATO FLAKES, POTATO STAR\n",
            "/content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1/crop_5.jpg: TAPIOCA STARCH, TAPARY BEANS (MOTH DAL)\n",
            "/content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1/crop_6.jpg: FLOUR, LODISED SALT, RED CHILLI POWDER,\n",
            "/content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1/crop_7.jpg: BLACK SALT, ACIDITY REGULATOR (INS 330),\n",
            "/content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1/crop_8.jpg: BLACK PEPPER, CLOVE, CARDAMOM, DRIED\n",
            "/content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1/crop_9.jpg: GINGER POWDER, DRIED GARLIC POWDER, REFINED\n",
            "/content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1/crop_10.jpg: SUGAR, CUMIN POWDER, BAY LEAVES,\n",
            "/content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1/crop_11.jpg: NUTMEG, CINNAMON AND MINT LEAVES\n",
            "/content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1/crop_12.jpg: CONTAINS ADDED NATURAL, NATURE IDENTICAL &\n",
            "/content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1/crop_13.jpg: ARTIFICIAL FLAVOURING SUBSTANCES (MINT)\n",
            "/content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1/crop_14.jpg: ALLERGY ADVICE:\n",
            "/content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1/crop_15.jpg: MAY CONTAIN PEANUT, TREE NUTS, SESAME\n",
            "/content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1/crop_16.jpg: SEED, MILK, SOYA, MUSTARD SEED & GLUTEN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# =========================\n",
        "# Print & Save results\n",
        "# =========================\n",
        "main_img_name = os.path.splitext(os.path.basename(cropped_folder))[0]\n",
        "jsonl_out_path = os.path.join(cropped_folder, f\"{main_img_name}.jsonl\")\n",
        "\n",
        "with open(jsonl_out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for img_path, text in zip(image_paths, ocr_texts):\n",
        "        img_name = os.path.basename(img_path)  # only file name, not full path\n",
        "        record = {\"image\": img_name, \"text\": text}\n",
        "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")  # write one JSON object per line\n",
        "        print(f\"{img_name}: {text}\")\n",
        "\n",
        "print(f\"✅ OCR results saved to {jsonl_out_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctQeke2U0Q5y",
        "outputId": "bdd5b621-7b68-422a-c276-82436ac22c5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "crop_1.jpg: IG\n",
            "crop_2.jpg: INGREDIENTS:\n",
            "crop_3.jpg: POTATO, REFINED PALMOLEIN OIL, BENGAL GRAM\n",
            "crop_4.jpg: FLOUR (BESAN), POTATO FLAKES, POTATO STAR\n",
            "crop_5.jpg: TAPIOCA STARCH, TAPARY BEANS (MOTH DAL)\n",
            "crop_6.jpg: FLOUR, LODISED SALT, RED CHILLI POWDER,\n",
            "crop_7.jpg: BLACK SALT, ACIDITY REGULATOR (INS 330),\n",
            "crop_8.jpg: BLACK PEPPER, CLOVE, CARDAMOM, DRIED\n",
            "crop_9.jpg: GINGER POWDER, DRIED GARLIC POWDER, REFINED\n",
            "crop_10.jpg: SUGAR, CUMIN POWDER, BAY LEAVES,\n",
            "crop_11.jpg: NUTMEG, CINNAMON AND MINT LEAVES\n",
            "crop_12.jpg: CONTAINS ADDED NATURAL, NATURE IDENTICAL &\n",
            "crop_13.jpg: ARTIFICIAL FLAVOURING SUBSTANCES (MINT)\n",
            "crop_14.jpg: ALLERGY ADVICE:\n",
            "crop_15.jpg: MAY CONTAIN PEANUT, TREE NUTS, SESAME\n",
            "crop_16.jpg: SEED, MILK, SOYA, MUSTARD SEED & GLUTEN\n",
            "✅ OCR results saved to /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1/in1.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# extracting Ingredients"
      ],
      "metadata": {
        "id": "OEwBf39S7kRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copy from drive to colab memory\n",
        "!cp -r \"/content/drive/MyDrive/Thesis/ingredient-model\" \"./ingredient-model\""
      ],
      "metadata": {
        "id": "lpqn0C76HLnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
        "\n",
        "model_path = \"./ingredient-model\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
        "\n",
        "ner_pipeline = pipeline(\n",
        "    \"token-classification\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    aggregation_strategy=\"simple\",\n",
        "    device=0  # GPU\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzbRLdkmLLBx",
        "outputId": "8f11d3bc-a34f-4e1b-caee-9a1fbb6e063d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "input_file = jsonl_out_path\n",
        "\n",
        "texts = []\n",
        "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "        texts.append(data[\"text\"])\n",
        "# Merge with newline and convert to lowercase\n",
        "merged_text = \" \".join(texts).lower()\n",
        "print(merged_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx74f6pnOAk0",
        "outputId": "cb8067ef-cc11-4e02-c88b-55fb4a381893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ig ingredients: potato, refined palmolein oil, bengal gram flour (besan), potato flakes, potato star tapioca starch, tapary beans (moth dal) flour, lodised salt, red chilli powder, black salt, acidity regulator (ins 330), black pepper, clove, cardamom, dried ginger powder, dried garlic powder, refined sugar, cumin powder, bay leaves, nutmeg, cinnamon and mint leaves contains added natural, nature identical & artificial flavouring substances (mint) allergy advice: may contain peanut, tree nuts, sesame seed, milk, soya, mustard seed & gluten\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = ner_pipeline(merged_text, batch_size=16)\n",
        "for r in results:\n",
        "    print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcUnEs7zOejq",
        "outputId": "ea87d12b-4b0c-4192-d10b-6223478ef47a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'entity_group': 'ING', 'score': np.float32(0.9998621), 'word': 'potato , refined palmolein oil , bengal gram flour ( besan ) , potato flakes , potato star tapioca starch , tapary beans ( moth dal ) flour , lodised salt , red chilli powder , black salt , acidity regulator ( ins 330 ) , black pepper , clove , cardamom , dried ginger powder , dried garlic powder , refined sugar , cumin powder , bay leaves , nutmeg , cinnamon and mint leaves', 'start': 16, 'end': 368}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# Example image name\n",
        "image_name = main_img_name   # <-- set dynamically if you loop over images\n",
        "\n",
        "# Directory in Google Drive where files will be stored\n",
        "output_dir = cropped_folder\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# === Save raw predictions JSONL ===\n",
        "pred_file = os.path.join(output_dir, f\"{image_name}_ingredients_pred.jsonl\")\n",
        "with open(pred_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    for r in results:\n",
        "        # Convert numpy.float32 → normal float\n",
        "        r[\"score\"] = float(r[\"score\"])\n",
        "        f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(f\"Saved raw predictions → {pred_file}\")\n",
        "\n",
        "\n",
        "# === Filter texts by threshold ===\n",
        "def filter_texts(jsonl_path, threshold=0.95):\n",
        "    filtered = []\n",
        "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            data = json.loads(line)\n",
        "            if data[\"score\"] >= threshold:\n",
        "                filtered.append(data[\"word\"])\n",
        "    return filtered\n",
        "\n",
        "\n",
        "threshold = 0.97  # <-- user-given threshold\n",
        "filtered_texts = filter_texts(pred_file, threshold=threshold)\n",
        "\n",
        "# === Save filtered texts to TXT file ===\n",
        "final_jsonl_file = os.path.join(output_dir, f\"{image_name}_final_ingredients.jsonl\")\n",
        "with open(final_jsonl_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    for txt in filtered_texts:\n",
        "        json_line = {\"ingredient\": txt}\n",
        "        f.write(json.dumps(json_line, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(f\"Saved filtered ingredients → {final_jsonl_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwYiIGwsVL1R",
        "outputId": "440aecfa-8d08-448c-b63c-ff8b219a6be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved raw predictions → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1/in1_ingredients_pred.jsonl\n",
            "Saved filtered ingredients → /content/drive/MyDrive/Thesis/surya/surya_input_images/detected_images/in1/in1_final_ingredients.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "detects but the recognision takes lifetime"
      ],
      "metadata": {
        "id": "5oXCGDDyorBy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMngkP_UYbTA"
      },
      "outputs": [],
      "source": [
        "# from PIL import Image\n",
        "# from surya.foundation import FoundationPredictor\n",
        "# from surya.recognition import RecognitionPredictor\n",
        "# from surya.detection import DetectionPredictor\n",
        "# IMAGE_PATH = \"/content/binary_text.png\"\n",
        "# image = Image.open(IMAGE_PATH)\n",
        "# foundation_predictor = FoundationPredictor()\n",
        "# recognition_predictor = RecognitionPredictor(foundation_predictor)\n",
        "# detection_predictor = DetectionPredictor()\n",
        "\n",
        "# predictions = recognition_predictor([image], det_predictor=detection_predictor)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import glob, shutil\n",
        "\n",
        "# for ckpt in glob.glob(\"./results\"):\n",
        "#     shutil.rmtree(ckpt, ignore_errors=True)"
      ],
      "metadata": {
        "id": "CITc5Iirkf9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LANGUAGE Detection (accuracy unacceptable)"
      ],
      "metadata": {
        "id": "4acYwGn59--K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imcQA3Uj8LgP",
        "outputId": "c6bf6f28-bcd6-4b5d-d8c8-577cea869829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-3.0.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.0.2)\n",
            "Using cached pybind11-3.0.0-py3-none-any.whl (292 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp311-cp311-linux_x86_64.whl size=4508431 sha256=6fda5d03ba9426ed92428ffda2ff9e06629c2c36d84f9bb7590887225977d398\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/35/5057db0249224e9ab55a513fa6b79451473ceb7713017823c3\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.ftz\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgzj5ksN8PvX",
        "outputId": "40ba6917-fe21-4000-d7d5-214427f5664a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-17 21:31:33--  https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.157.254.124, 108.157.254.15, 108.157.254.102, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.157.254.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 131266198 (125M) [application/octet-stream]\n",
            "Saving to: ‘lid.176.bin’\n",
            "\n",
            "lid.176.bin         100%[===================>] 125.18M   196MB/s    in 0.6s    \n",
            "\n",
            "2025-08-17 21:31:33 (196 MB/s) - ‘lid.176.bin’ saved [131266198/131266198]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "import json\n",
        "import os\n",
        "\n",
        "# =========================\n",
        "# Load fastText language identification model\n",
        "# =========================\n",
        "lang_model_path = \"/content/drive/MyDrive/Thesis/surya/fasttext/lid.176.bin\"\n",
        "lang_model = fasttext.load_model(lang_model_path)\n",
        "\n",
        "# =========================\n",
        "# OCR outputs from TrOCR\n",
        "# =========================\n",
        "# ocr_texts = [\"some text from crop_1.jpg\", \"another text from crop_2.jpg\", ...]\n",
        "\n",
        "# =========================\n",
        "# Predict languages\n",
        "# =========================\n",
        "pred_labels, pred_probs = lang_model.predict(ocr_texts)  # batch prediction\n",
        "\n",
        "# =========================\n",
        "# Combine results\n",
        "# =========================\n",
        "results = []\n",
        "for text, label, prob in zip(ocr_texts, pred_labels, pred_probs):\n",
        "    lang = label[0].replace(\"__label__\", \"\")  # remove fastText prefix\n",
        "    lang_conf = float(prob[0])\n",
        "    results.append({\n",
        "        \"text\": text,\n",
        "        \"lang\": lang,\n",
        "        \"lang_conf\": lang_conf\n",
        "    })\n",
        "\n",
        "# =========================\n",
        "# Print results\n",
        "# =========================\n",
        "for r in results:\n",
        "    print(r)\n",
        "\n",
        "# =========================\n",
        "# Optional: Save to JSONL\n",
        "# =========================\n",
        "# jsonl_path = os.path.join(os.path.dirname(lang_model_path), \"ocr_lang_results.jsonl\")\n",
        "# with open(jsonl_path, \"w\", encoding=\"utf-8\") as f:\n",
        "#     for r in results:\n",
        "#         f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "# print(f\"✅ Language detection results saved to {jsonl_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH5sGf2o9MWR",
        "outputId": "75bdc63e-1937-4f12-e106-33e698bcaa55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'IG', 'lang': 'pt', 'lang_conf': 0.4512484073638916}\n",
            "{'text': 'INGREDIENTS:', 'lang': 'en', 'lang_conf': 0.33771204948425293}\n",
            "{'text': 'POTATO, REFINED PALMOLEIN OIL, BENGAL GR', 'lang': 'ca', 'lang_conf': 0.18098032474517822}\n",
            "{'text': 'FLOUR (BESAN), POTATO FLAKES, POTATO', 'lang': 'en', 'lang_conf': 0.778530478477478}\n",
            "{'text': 'TAPIOCA STARCH, TAPARY BEANS (MOTH DAL)', 'lang': 'en', 'lang_conf': 0.556109607219696}\n",
            "{'text': 'FLOUR, LODISED SALT, RED CHILLI POWDER,', 'lang': 'en', 'lang_conf': 0.5090453624725342}\n",
            "{'text': 'BLACK SALT, ACIDITY REGULATOR (INS 330),', 'lang': 'pl', 'lang_conf': 0.17589902877807617}\n",
            "{'text': 'BLACK PEPPER, CLOVE, CARDAMOM, DRIED', 'lang': 'fr', 'lang_conf': 0.1322389543056488}\n",
            "{'text': 'GINGER POWDER, DRIED GARLIC POWDER, REFINED', 'lang': 'en', 'lang_conf': 0.38636747002601624}\n",
            "{'text': 'SUGAR, CUMIN POWDER, BAY LEAVES,', 'lang': 'en', 'lang_conf': 0.41062816977500916}\n",
            "{'text': 'NUTMEG, CINNAMON AND MINT LEAVES', 'lang': 'en', 'lang_conf': 0.910754382610321}\n",
            "{'text': 'CONTAINS ADDED NATURAL, NATURE IDENTICAL &', 'lang': 'en', 'lang_conf': 0.234722301363945}\n",
            "{'text': 'ARTIFICIAL FLAVOURING SUBSTANCES (MINT)', 'lang': 'en', 'lang_conf': 0.3517216444015503}\n",
            "{'text': 'ALLERGY ADVICE:', 'lang': 'en', 'lang_conf': 0.6676422357559204}\n",
            "{'text': 'MAY CONTAIN PEANUT, TREE NUTS, SESAME', 'lang': 'en', 'lang_conf': 0.49955788254737854}\n",
            "{'text': 'SEED, MILK, SOYA, MUSTARD SEED & GLUTEN', 'lang': 'en', 'lang_conf': 0.3118468225002289}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *DETECTS* PARA. WORKS FINE"
      ],
      "metadata": {
        "id": "uYGYb1lYmzlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !surya_layout /content/binary_text.png --images"
      ],
      "metadata": {
        "id": "LVrWfYv_lqgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "donot work"
      ],
      "metadata": {
        "id": "c4tVLRAkm2Ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from PIL import Image, ImageDraw\n",
        "# from surya.layout import LayoutPredictor\n",
        "\n",
        "# IMAGE_PATH = \"/content/binary_text.png\"\n",
        "# image = Image.open(IMAGE_PATH)\n",
        "\n",
        "# # Initialize layout predictor\n",
        "# layout_predictor = LayoutPredictor()\n",
        "\n",
        "# # Run layout prediction (returns dict for each image)\n",
        "# layout_predictions = layout_predictor([image])[0]\n",
        "\n",
        "# # Copy image for drawing\n",
        "# drawn = image.copy()\n",
        "# draw = ImageDraw.Draw(drawn)\n",
        "\n",
        "# # Loop over bounding boxes and labels\n",
        "# for bbox, label in zip(layout_predictions[\"bboxes\"], layout_predictions[\"labels\"]):\n",
        "#     x_min, y_min, x_max, y_max = bbox\n",
        "#     # Draw rectangle\n",
        "#     draw.rectangle([x_min, y_min, x_max, y_max], outline=\"red\", width=3)\n",
        "#     # Draw label text above the box\n",
        "#     draw.text((x_min, max(0, y_min-12)), label, fill=\"red\")\n",
        "\n",
        "# # Save & show\n",
        "# drawn.save(\"layout_detected.png\")\n",
        "# drawn.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "aGOLK18_juNg",
        "outputId": "12b1a3a8-2b7e-4599-e8f1-64102a42e031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Recognizing layout: 100%|██████████| 1/1 [00:20<00:00, 20.02s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'LayoutResult' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1756492273.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Loop over bounding boxes and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayout_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bboxes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mx_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Draw rectangle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'LayoutResult' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "takes lifetime"
      ],
      "metadata": {
        "id": "K6t2epCQo-yO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!surya_ocr /content/binary_text.png --images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIckftP9m-Wk",
        "outputId": "99c5d0fc-0de1-4cb7-f3f2-8e557e5861a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-17 10:38:46.209770: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1755427126.251209    9533 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1755427126.264737    9533 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1755427126.299677    9533 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755427126.299740    9533 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755427126.299745    9533 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755427126.299749    9533 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Detecting bboxes: 100% 1/1 [00:36<00:00, 36.18s/it]\n",
            "Recognizing Text:   0% 0/44 [00:00<?, ?it/s]\n",
            "Aborted!\n",
            "Recognizing Text:   0% 0/44 [02:07<?, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2708cf17"
      },
      "source": [
        "!pip install contextualSpellCheck"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02c3a8a0"
      },
      "source": [
        "import spacy\n",
        "import contextualSpellCheck\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "contextualSpellCheck.add_to_pipe(nlp)\n",
        "doc = nlp(filtered_texts)\n",
        "\n",
        "print(doc._.performed_spellCheck) #Should be True\n",
        "print(doc._.outcome_spellCheck) #Income was $9.4 million compared to the prior year of $2.7 million."
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "4acYwGn59--K",
        "uYGYb1lYmzlo"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}